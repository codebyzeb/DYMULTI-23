{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd01e8db04b6222e005183a25ca661b7fa6df7c615864ec3c86b7d4844b2aa66417",
   "display_name": "Python 3.9.1 64-bit ('wordseg': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Corpus Analysis\n",
    "\n",
    "This python notebook contains various calculations to do with the corpora used in the study. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHILDES_PHONEMIZED = \"../../Corpora/CHILDES_wordseg/phonemized/\"\n",
    "CHILDES_FILES = [CHILDES_PHONEMIZED+file for file in os.listdir(CHILDES_PHONEMIZED) if \".txt\" in file]\n",
    "CHILDES_FILES.sort()\n",
    "\n",
    "BR_FILE = \"../data/br-phonemes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phones(files):\n",
    "    phones = []\n",
    "    for file in files:\n",
    "        f = open(file, 'r').readlines()\n",
    "        for line in f:\n",
    "            for p in line.strip().split(' '):\n",
    "                if not p in phones and p != ';eword':\n",
    "                    phones.append(p)\n",
    "    return phones\n",
    "\n",
    "def find_phone(phone):\n",
    "    for file in CHILDES_FILES:\n",
    "        if phone in get_phones([file]):\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = [\"Basque\", \"Cantonese\", \"Croatian\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Farsi\", \"French\", \"German\", \"Greek\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Irish\", \"Italian\", \"Japanese\", \"Korean\", \"Mandarin\", \"Norwegian\", \"Portuguese\", \"Romanian\", \"Serbian\", \"Spanish\", \"Swedish\", \"Turkish\"]\n",
    "CHILDES_FILES_USED = [list(filter(lambda x : language in x, CHILDES_FILES))[0] for language in LANGUAGES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['a', 'ɣ', 'u', 'ɾ', 'l', 'tʃ', 'aʊ', 'k', 'e', 'o', 's̻', 'β', 'n', 'ɡ', 'eɪ', 'm', 'i', 'p', 't', 'θ', '', 'b', 'aɪ', 'ð', 'ʎ', 'oɪ', 'd', 'ts̻', 'ts̺', 'ɲ', 's̺', 'r', 'ɟ', 'f', 'j', 'ʃ', 'x', 'eʊ', 'c', 'aaɜ', 'z', 'eoɜ', 'onɡ', 'ei', 'inɡɜ', 'au', 'ou', 'yu', 'h', 'ai', 'ɹ', 'iː', 'ɑː', 'aa', 'aɜ', 'oɜ', 'ŋ', 'eɜ', 'w', 'aau', 'inɡ', 'uː', 's', 'ouɜ', 'iu', 'oiɜ', 'nɡ', 'eoiɜ', 'ɒ', 'ɛ', 'oenɡ', 'ə', 'eo', 'ɔːɔː', 'ui', 'onɡɜ', 'ʌ', 'oenɡɜ', 'yuɜ', 'eoi', 'anɡ', 'unɡ', 'iuɜ', 'aai', 'iɜ', 'aaiɜ', 'ɪ', 'unɡɜ', 'enɡɜ', 'dʒ', 'oi', 'anɡɜ', 'ɐɐ', 'v', 'eiɜ', 'auɜ', 'aiɜ', 'enɡ', 'aanɡ', 'əə', 'aauɜ', 'uɜ', 'ələl', 'ɔɪ', 'oeɜ', 'ɑːɑː', 'ii', 'ɜː', 'ʊ', 'əʊəʊ', 'uiɜ', 'ɔː', 'oe', 'eə', 'aɪə', 'æ', 'ɑ', 'ts', 'dʑ', 'l̩', 'tɕ', 'ʒ', 'aː', 'oʊ', 'ɐ̯', 'ʔu', 'ʋ', 'ʔœ', '?ɑ', 'ε', 'ʔe', 'ʔʌ', 'ʔi', 'ʔy', 'ɔ', 'ʁ', 'œ', 'ʔo', '?a', 'ɜ', 'y', 'ɒɒ', 'œː', 'ɑɑ', 'ʌː', 'j-', 'əʊ', 'oː', 'ʔeː', 'œy', 'ɵ', 'eː', 'ʌʊ', 'øː', 'ɪː', 'yʊ', 'tʲ', 'ɛɪ', 'pː', 'əʲ', 'ʔ', 'ɛː', 'ʀ', 'r̩', 'ɕ', '1', 'ɫ', 'pʰə', 'ʑ', 'm̩', 'ʲ', 'əː', 'ʝ', 'dʒʰa', 'əl', 'ɔ̃', 'tʰ', 'əʰa', 'ŋ̩ʰə', 'q', 'ɳ', 'ɚ', 'ɑːɹ', 'ɐ', 'ʊɹ', 'ᵻ', 'ɛɹ', 'ɪɹ', 'oːɹ', 'aɪɚ', 'ɔːɹ', 'n̩', 'iə', 'ɑ̃', 'ææ', 'ʊə', '�', 'ɯ', 'bʲ', 'g', 'ɸ', 't͡s', 'mʲ', 'kʲ', 'rʲ', 'pʲ', 'ç', 'gʲ', 'ɯː', 'tː', 't^', 'kː', 'd^', 's^', 'æi', 't^ː', 'yː', 'ø', 'yi', 'æː', 'æiː', 'ɵː', 'øi', 'ə-', 'ɛ̃', 'œ̃', 'a-', 'e-', 'y-', 'ʏ', 'ɔø', 'ʊɐ', 'pf', 'ɟː', 'tsː', 'tʃː', 'bː', 'dː', 'cː', 'ɡː', 'dzː', 'r#', 'eɪː', 'ŋ#', 'n#', 'aʊː', 'øyː', 'oʊː', 'aɪː', 'l#', 'øy', 'tl#', 'm#', 'ɲ#', 'χ', 'd̪', 'A', 't̪', 'nʲ', 'lʲ', 'uə', 'dʲ', 'i̯', 'hʲ', 'ɡʲ', 'çʲ', 'ŋʲ', 'fʲ', 'ŭ', 'xʲ', 'ss', 'dz', 'dʒː', 'mː', 't-', 'k-', 'kh', 'ph', 's-', 'q-', 'p-', 'd-', 'ɑu', 'ər', 'iou', 'tɕh', 'i̪', 'tsh', 'iɑ', 'th', 'uei', 'uo', 'ʐ', 'iɛ', 'io', 'yɛ', 'uai', 'ərɜ', 'ʉː', 'ʉ', 'ʂ', 'ʉɪ', 'ɑɪ', 'ʊː', 'ɐ̃ʊ̃', 'ɐ̃', 'ũ', 'ɛʊ', 'iʊ', 'õ', 'uɪ', 'ɨ', '(pt-pt)', 'sʲ', 'tʃʲ', 'əɪ', 'zʲʲ', 'ea', 'ʃʲʲ', 'tsʲʲ', 'nʲʲ', 'iɪ', 'tʲʲ', 'ɾʲʲ', 'ɔa', 'mʲʲ', 'bʲʲ', 'tsʲ', 'lʲʲ', 'dʒʲ', 'dʲʲ', 'vʲ', 'pʲʲ', 'ʃʲ', 'ɾʲ', 'fʲʲ', 'ʒʲʲ', 'vʲʲ', 'sx', 'ɯɯ']\n"
     ]
    }
   ],
   "source": [
    "print(get_phones(CHILDES_FILES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../../Corpora/CHILDES_wordseg/phonemized/Irish_Gaeltacht_Gaeltacht_10000utterances_phonemes.txt\n"
     ]
    }
   ],
   "source": [
    "find_phone(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['ɯː', 'n', 'ɯ', 'j', 'o', 'i', 'ʃ', 'd', 'r', 'e', 'g', 'a', 'k', 'oː', 'h', 'dʒ', 'z', 't', 'aː', 'eː', 'm', '�', 'tʃ', 'w', 'b', 'pʲ', 'p', 't͡s', 'ɲ', 'ɸ', 'rʲ', 'kʲ', 'ç', 'bʲ', 'gʲ'] 35\n"
     ]
    }
   ],
   "source": [
    "a = get_phones([x for x in CHILDES_FILES_USED if \"Jap\" in x])\n",
    "print(a, len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_token_ratio(file):\n",
    "    f = open(file, 'r').readlines()\n",
    "    types = collections.Counter()\n",
    "    for line in f:\n",
    "        words = [word.strip().split(' ') for word in line.split(';eword')]\n",
    "        word_strs = [''.join(word) for word in words if word != [] and word != ['']]\n",
    "        types.update(word_strs)\n",
    "    return len(types)/sum(types[k] for k in types)\n",
    "\n",
    "def get_phones_per_word(file):\n",
    "    f = open(file, 'r').readlines()\n",
    "    lengths = collections.Counter()\n",
    "    for line in f:\n",
    "        words = [word.strip().split(' ') for word in line.split(';eword')]\n",
    "        word_lengths = [len(word) for word in words if word != [] and word != ['']]\n",
    "        lengths.update(word_lengths)\n",
    "    return sum([k * lengths[k] for k in lengths])/sum([lengths[k] for k in lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.7085392993357003 0.6808417183682755\n"
     ]
    }
   ],
   "source": [
    "ppw = np.array([get_phones_per_word(CHILDES_FILES_USED[i]) for i in range(len(CHILDES_FILES_USED))])\n",
    "print(np.mean(ppw), np.std(ppw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.09089396847085207 0.049873222560843575\n"
     ]
    }
   ],
   "source": [
    "ttrs = np.array([get_type_token_ratio(CHILDES_FILES_USED[i]) for i in range(len(CHILDES_FILES_USED))])\n",
    "print(np.mean(ttrs), np.std(ttrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.039668034874314646\n"
     ]
    }
   ],
   "source": [
    "print(get_type_token_ratio(BR_FILE))"
   ]
  },
  {
   "source": [
    "# Check Syllabic Sounds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPA_SYLLABIC_SOUNDS = ['ɪ','ɐ','ʊ','i','ĩ','ĭ','ɨ','y','ỹ','ȳ','u','ʉ','ɯ','u','ʏ','ũ','ŭ','ʌ','ɞ','ü',\n",
    "                        'ø','ɵ','ɤ','o','œ','œ','ö','œ','ɔ','ọ','õ','ŏ','ɵ','e','ɘ','ə','ɜ','ẹ','ɛ','ε','ɚ','ẽ','ĕ',\n",
    "                        'æ','ɐ','a','ä','ɑ','ɒ','ã','ă','α']+['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_syllabic(file):\n",
    "    wrong = collections.Counter()\n",
    "    for line in open(file, 'r').readlines():\n",
    "        word = \"\"\n",
    "        is_syllabic = False\n",
    "        for p in line.strip().split(' '):\n",
    "            if p == \";eword\":\n",
    "                if not is_syllabic:\n",
    "                    wrong[word]+=1\n",
    "                is_syllabic = False\n",
    "                word = \"\"\n",
    "            else:\n",
    "                word += p\n",
    "                for s in IPA_SYLLABIC_SOUNDS:\n",
    "                    if s in p:\n",
    "                        is_syllabic = True\n",
    "    return wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "../../Corpora/CHILDES_wordseg/phonemized/PortugueseBR_Florianopolis_Florianopolis_10000utterances_phonemes.txt\n",
      "Counter({'sj': 69, 'dʒj': 60, 'kj': 18, 'mj': 7, 'tʃj': 3, 'p': 2, 'fj': 1, 'm': 1, 'vj': 1, 'lj': 1})\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "i = 20\n",
    "print(CHILDES_FILES_USED[i])\n",
    "l = check_for_syllabic(CHILDES_FILES_USED[i])\n",
    "print(l)\n",
    "print(sum([l[x] for x in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}